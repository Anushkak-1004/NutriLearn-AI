{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üçï NutriLearn AI - Food Classification Model Training\n",
        "\n",
        "Train a deep learning model for food recognition using the Food-101 dataset with transfer learning.\n",
        "\n",
        "**What you'll learn:**\n",
        "- Transfer learning with PyTorch (MobileNetV2/EfficientNet/ResNet50)\n",
        "- Data augmentation for image classification\n",
        "- MLflow experiment tracking\n",
        "- Model evaluation with confusion matrix\n",
        "- Model deployment preparation\n",
        "\n",
        "**Steps:**\n",
        "1. ‚ö° Enable GPU (Runtime ‚Üí Change runtime type ‚Üí GPU ‚Üí Save)\n",
        "2. üì¶ Run setup cells to install dependencies\n",
        "3. üéØ Train model (choose architecture)\n",
        "4. üìä View results and metrics\n",
        "5. üíæ Download trained model\n",
        "\n",
        "**Hardware Requirements:**\n",
        "- GPU strongly recommended (T4 or better)\n",
        "- Training time: ~1-2 hours on T4 GPU, ~15+ hours on CPU\n",
        "\n",
        "**Dataset:** Food-101 (101 food categories, 101,000 images, ~5GB)"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Setup Environment"
      ],
      "metadata": {
        "id": "setup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check GPU availability and system info\n",
        "import torch\n",
        "import sys\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"SYSTEM INFORMATION\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Python version: {sys.version.split()[0]}\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"\\nGPU Available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"‚úÖ GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"‚úÖ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "    print(f\"‚úÖ CUDA Version: {torch.version.cuda}\")\n",
        "    device = torch.device('cuda')\n",
        "    print(\"\\nüöÄ Training will be FAST on GPU!\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No GPU detected. Training will be VERY slow!\")\n",
        "    print(\"   Enable GPU: Runtime ‚Üí Change runtime type ‚Üí GPU ‚Üí Save\")\n",
        "    print(\"   Then: Runtime ‚Üí Restart runtime\")\n",
        "    device = torch.device('cpu')\n",
        "    print(\"\\nüêå Training will take 15+ hours on CPU\")\n",
        "\n",
        "print(f\"\\nUsing device: {device}\")\n",
        "print(\"=\" * 60)"
      ],
      "metadata": {
        "id": "check_gpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "print(\"Installing dependencies...\")\n",
        "!pip install -q mlflow scikit-learn matplotlib seaborn tqdm Pillow\n",
        "print(\"‚úÖ All packages installed successfully!\")\n",
        "\n",
        "# Import libraries\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(\"‚úÖ Libraries imported successfully!\")"
      ],
      "metadata": {
        "id": "install_deps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mount Google Drive (Optional)\n",
        "\n",
        "Mount Google Drive to save models persistently. Skip this if you'll download models directly."
      ],
      "metadata": {
        "id": "mount_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive to save models\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create directory for saving models\n",
        "DRIVE_MODEL_DIR = '/content/drive/MyDrive/NutriLearn_Models'\n",
        "os.makedirs(DRIVE_MODEL_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"‚úÖ Google Drive mounted\")\n",
        "print(f\"‚úÖ Models will be saved to: {DRIVE_MODEL_DIR}\")"
      ],
      "metadata": {
        "id": "mount_drive"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Clone Repository and Setup"
      ],
      "metadata": {
        "id": "clone"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone repository (replace with your repo URL if you have one)\n",
        "# Option 1: Clone from GitHub\n",
        "# !git clone https://github.com/yourusername/nutrilearn-ai.git\n",
        "# %cd nutrilearn-ai/backend\n",
        "\n",
        "# Option 2: Download training script directly\n",
        "!wget -q https://raw.githubusercontent.com/yourusername/nutrilearn-ai/main/backend/train_model.py\n",
        "\n",
        "# Option 3: Create training script inline (see next cell)\n",
        "print(\"‚úÖ Setup complete\")\n",
        "print(\"\\nNote: If you have the train_model.py script, upload it using the Files panel on the left\")"
      ],
      "metadata": {
        "id": "clone_repo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Preview\n",
        "\n",
        "Let's download a small sample and visualize the Food-101 dataset before training."
      ],
      "metadata": {
        "id": "dataset_preview_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and preview Food-101 dataset\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "print(\"Downloading Food-101 dataset (this may take 5-10 minutes)...\")\n",
        "print(\"Dataset size: ~5GB\")\n",
        "\n",
        "# Download dataset\n",
        "dataset = torchvision.datasets.Food101(\n",
        "    root='./data',\n",
        "    split='train',\n",
        "    download=True\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úÖ Dataset downloaded!\")\n",
        "print(f\"Total training images: {len(dataset)}\")\n",
        "print(f\"Number of classes: {len(dataset.classes)}\")\n",
        "print(f\"\\nFirst 10 food categories:\")\n",
        "for i, cls in enumerate(dataset.classes[:10]):\n",
        "    print(f\"  {i}: {cls}\")"
      ],
      "metadata": {
        "id": "download_dataset"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize sample images from different classes\n",
        "fig, axes = plt.subplots(3, 4, figsize=(15, 12))\n",
        "fig.suptitle('Sample Food Images from Food-101 Dataset', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Select random samples\n",
        "random_indices = random.sample(range(len(dataset)), 12)\n",
        "\n",
        "for idx, ax in enumerate(axes.flat):\n",
        "    img, label = dataset[random_indices[idx]]\n",
        "    ax.imshow(img)\n",
        "    ax.set_title(f\"{dataset.classes[label]}\", fontsize=10)\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüìä Dataset Statistics:\")\n",
        "print(f\"  Images per class: ~1,000\")\n",
        "print(f\"  Total classes: 101\")\n",
        "print(f\"  Image format: RGB\")\n",
        "print(f\"  Typical size: 512x512 pixels\")"
      ],
      "metadata": {
        "id": "visualize_samples"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Augmentation Preview\n",
        "\n",
        "See how data augmentation transforms images during training."
      ],
      "metadata": {
        "id": "augmentation_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show data augmentation effects\n",
        "from torchvision import transforms\n",
        "\n",
        "# Define augmentation pipeline\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Get a sample image\n",
        "sample_img, sample_label = dataset[random.randint(0, len(dataset)-1)]\n",
        "sample_class = dataset.classes[sample_label]\n",
        "\n",
        "# Apply augmentation multiple times\n",
        "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
        "fig.suptitle(f'Data Augmentation Examples: {sample_class}', fontsize=14, fontweight='bold')\n",
        "\n",
        "# Original image\n",
        "axes[0, 0].imshow(sample_img)\n",
        "axes[0, 0].set_title('Original', fontweight='bold')\n",
        "axes[0, 0].axis('off')\n",
        "\n",
        "# Augmented versions\n",
        "for i in range(7):\n",
        "    row = (i + 1) // 4\n",
        "    col = (i + 1) % 4\n",
        "    augmented = train_transform(sample_img)\n",
        "    # Convert tensor back to image\n",
        "    augmented_img = augmented.permute(1, 2, 0).numpy()\n",
        "    axes[row, col].imshow(augmented_img)\n",
        "    axes[row, col].set_title(f'Augmented {i+1}')\n",
        "    axes[row, col].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüìù Augmentation techniques applied:\")\n",
        "print(\"  ‚úì Random cropping and resizing\")\n",
        "print(\"  ‚úì Random horizontal flipping\")\n",
        "print(\"  ‚úì Color jittering (brightness, contrast, saturation)\")\n",
        "print(\"  ‚úì Normalization with ImageNet statistics\")\n",
        "print(\"\\nThese augmentations help the model generalize better!\")"
      ],
      "metadata": {
        "id": "show_augmentation"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Train Model\n",
        "\n",
        "Now let's train the model! This will:\n",
        "- Use transfer learning with pre-trained models\n",
        "- Train for 20 epochs (adjustable)\n",
        "- Track experiments with MLflow\n",
        "- Save the best model automatically\n",
        "- Generate evaluation metrics\n",
        "\n",
        "**Choose your model architecture:**\n",
        "- **MobileNetV2**: Fast, lightweight (recommended for quick training)\n",
        "- **EfficientNet-B0**: Better accuracy, moderate speed\n",
        "- **ResNet50**: Best accuracy, slower training"
      ],
      "metadata": {
        "id": "train"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train with MobileNetV2 (fast, good accuracy)\n",
        "!python train_model.py \\\n",
        "    --model mobilenet_v2 \\\n",
        "    --epochs 20 \\\n",
        "    --batch_size 64 \\\n",
        "    --lr 0.001"
      ],
      "metadata": {
        "id": "train_mobilenet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Alternative: Train with EfficientNet (better accuracy, slower)"
      ],
      "metadata": {
        "id": "alt_train"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment to train with EfficientNet-B0\n",
        "# !python train_model.py \\\n",
        "#     --model efficientnet_b0 \\\n",
        "#     --epochs 25 \\\n",
        "#     --batch_size 48 \\\n",
        "#     --lr 0.001"
      ],
      "metadata": {
        "id": "train_efficientnet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. View Training Results\n",
        "\n",
        "Let's visualize the training progress and model performance."
      ],
      "metadata": {
        "id": "results"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training history\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check if training metrics exist\n",
        "if os.path.exists('ml-models/training_history.json'):\n",
        "    with open('ml-models/training_history.json', 'r') as f:\n",
        "        history = json.load(f)\n",
        "    \n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "    \n",
        "    # Plot loss\n",
        "    epochs = range(1, len(history['train_loss']) + 1)\n",
        "    ax1.plot(epochs, history['train_loss'], 'b-', label='Training Loss', linewidth=2)\n",
        "    ax1.plot(epochs, history['val_loss'], 'r-', label='Validation Loss', linewidth=2)\n",
        "    ax1.set_xlabel('Epoch', fontsize=12)\n",
        "    ax1.set_ylabel('Loss', fontsize=12)\n",
        "    ax1.set_title('Model Loss Over Time', fontsize=14, fontweight='bold')\n",
        "    ax1.legend(fontsize=10)\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Plot accuracy\n",
        "    ax2.plot(epochs, history['train_acc'], 'b-', label='Training Accuracy', linewidth=2)\n",
        "    ax2.plot(epochs, history['val_acc'], 'r-', label='Validation Accuracy', linewidth=2)\n",
        "    ax2.set_xlabel('Epoch', fontsize=12)\n",
        "    ax2.set_ylabel('Accuracy (%)', fontsize=12)\n",
        "    ax2.set_title('Model Accuracy Over Time', fontsize=14, fontweight='bold')\n",
        "    ax2.legend(fontsize=10)\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Print final metrics\n",
        "    print(\"\\nüìä Final Training Metrics:\")\n",
        "    print(f\"  Best Validation Accuracy: {max(history['val_acc']):.2f}%\")\n",
        "    print(f\"  Final Training Loss: {history['train_loss'][-1]:.4f}\")\n",
        "    print(f\"  Final Validation Loss: {history['val_loss'][-1]:.4f}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Training history not found. Train the model first!\")"
      ],
      "metadata": {
        "id": "plot_training"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display confusion matrix\n",
        "from IPython.display import Image, display\n",
        "import os\n",
        "\n",
        "if os.path.exists('ml-models/confusion_matrix.png'):\n",
        "    display(Image('ml-models/confusion_matrix.png'))\n",
        "else:\n",
        "    print(\"Confusion matrix not found (too many classes to visualize)\")"
      ],
      "metadata": {
        "id": "show_cm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show model config\n",
        "import json\n",
        "\n",
        "with open('ml-models/model_config.json', 'r') as f:\n",
        "    config = json.load(f)\n",
        "\n",
        "print(\"Model Configuration:\")\n",
        "print(json.dumps(config, indent=2))"
      ],
      "metadata": {
        "id": "show_config"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show class mappings (first 10)\n",
        "with open('ml-models/class_to_idx.json', 'r') as f:\n",
        "    class_to_idx = json.load(f)\n",
        "\n",
        "print(f\"Total classes: {len(class_to_idx)}\")\n",
        "print(\"\\nFirst 10 classes:\")\n",
        "for i, (name, idx) in enumerate(list(class_to_idx.items())[:10]):\n",
        "    print(f\"{idx}: {name}\")"
      ],
      "metadata": {
        "id": "show_classes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Model Evaluation and Testing\n",
        "\n",
        "Let's evaluate the model's performance and test it on sample images."
      ],
      "metadata": {
        "id": "test"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load evaluation results\n",
        "if os.path.exists('ml-models/evaluation_results.json'):\n",
        "    with open('ml-models/evaluation_results.json', 'r') as f:\n",
        "        eval_results = json.load(f)\n",
        "    \n",
        "    print(\"=\" * 60)\n",
        "    print(\"MODEL EVALUATION RESULTS\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"\\nüìä Overall Performance:\")\n",
        "    print(f\"  Top-1 Accuracy: {eval_results['top1_accuracy']:.2f}%\")\n",
        "    print(f\"  Top-5 Accuracy: {eval_results['top5_accuracy']:.2f}%\")\n",
        "    print(f\"  Total Test Samples: {eval_results['total_samples']:,}\")\n",
        "    \n",
        "    print(f\"\\nüèÜ Best Performing Classes:\")\n",
        "    for i, (cls, score) in enumerate(eval_results['best_classes'][:5], 1):\n",
        "        print(f\"  {i}. {cls}: {score:.2f}% F1-score\")\n",
        "    \n",
        "    print(f\"\\n‚ö†Ô∏è  Worst Performing Classes:\")\n",
        "    for i, (cls, score) in enumerate(eval_results['worst_classes'][:5], 1):\n",
        "        print(f\"  {i}. {cls}: {score:.2f}% F1-score\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Evaluation results not found\")"
      ],
      "metadata": {
        "id": "show_eval_results"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test inference on random samples\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "import random\n",
        "\n",
        "# Load model\n",
        "if os.path.exists('ml-models/food_model_v1.pth') and os.path.exists('ml-models/model_config.json'):\n",
        "    # Load config\n",
        "    with open('ml-models/model_config.json', 'r') as f:\n",
        "        config = json.load(f)\n",
        "    \n",
        "    with open('ml-models/class_to_idx.json', 'r') as f:\n",
        "        class_to_idx = json.load(f)\n",
        "    \n",
        "    idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
        "    \n",
        "    # Build model\n",
        "    model_name = config['model_name']\n",
        "    num_classes = config['num_classes']\n",
        "    \n",
        "    if model_name == 'mobilenet_v2':\n",
        "        model = models.mobilenet_v2(pretrained=False)\n",
        "        model.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(model.last_channel, num_classes)\n",
        "        )\n",
        "    \n",
        "    # Load weights\n",
        "    model.load_state_dict(torch.load('ml-models/food_model_v1.pth', map_location=device))\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    \n",
        "    # Preprocessing\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    \n",
        "    # Test on random samples\n",
        "    test_dataset = torchvision.datasets.Food101(root='./data', split='test', download=False)\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "    fig.suptitle('Model Predictions on Test Images', fontsize=16, fontweight='bold')\n",
        "    \n",
        "    for idx, ax in enumerate(axes.flat):\n",
        "        # Get random test image\n",
        "        rand_idx = random.randint(0, len(test_dataset)-1)\n",
        "        img, true_label = test_dataset[rand_idx]\n",
        "        true_class = test_dataset.classes[true_label]\n",
        "        \n",
        "        # Predict\n",
        "        input_tensor = preprocess(img).unsqueeze(0).to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_tensor)\n",
        "            probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
        "            top3_prob, top3_idx = torch.topk(probabilities, 3)\n",
        "        \n",
        "        # Get predictions\n",
        "        pred_class = idx_to_class[top3_idx[0][0].item()]\n",
        "        pred_conf = top3_prob[0][0].item() * 100\n",
        "        \n",
        "        # Display\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "        \n",
        "        # Color code: green if correct, red if wrong\n",
        "        color = 'green' if pred_class == true_class else 'red'\n",
        "        title = f\"True: {true_class}\\nPred: {pred_class} ({pred_conf:.1f}%)\"\n",
        "        ax.set_title(title, fontsize=9, color=color, fontweight='bold')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"\\n‚úÖ Inference test complete!\")\n",
        "    print(\"Green = Correct prediction, Red = Incorrect prediction\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Model files not found. Train the model first!\")"
      ],
      "metadata": {
        "id": "test_inference"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Download Trained Model\n",
        "\n",
        "Download all model files to use in your NutriLearn AI application."
      ],
      "metadata": {
        "id": "download"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a zip file with all model artifacts\n",
        "import zipfile\n",
        "from datetime import datetime\n",
        "\n",
        "# Create zip file\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "zip_filename = f'nutrilearn_model_{timestamp}.zip'\n",
        "\n",
        "with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
        "    # Add model files\n",
        "    if os.path.exists('ml-models/food_model_v1.pth'):\n",
        "        zipf.write('ml-models/food_model_v1.pth', 'food_model_v1.pth')\n",
        "        print(\"‚úì Added: food_model_v1.pth\")\n",
        "    \n",
        "    if os.path.exists('ml-models/class_to_idx.json'):\n",
        "        zipf.write('ml-models/class_to_idx.json', 'class_to_idx.json')\n",
        "        print(\"‚úì Added: class_to_idx.json\")\n",
        "    \n",
        "    if os.path.exists('ml-models/model_config.json'):\n",
        "        zipf.write('ml-models/model_config.json', 'model_config.json')\n",
        "        print(\"‚úì Added: model_config.json\")\n",
        "    \n",
        "    if os.path.exists('ml-models/evaluation_results.json'):\n",
        "        zipf.write('ml-models/evaluation_results.json', 'evaluation_results.json')\n",
        "        print(\"‚úì Added: evaluation_results.json\")\n",
        "    \n",
        "    if os.path.exists('ml-models/confusion_matrix.png'):\n",
        "        zipf.write('ml-models/confusion_matrix.png', 'confusion_matrix.png')\n",
        "        print(\"‚úì Added: confusion_matrix.png\")\n",
        "\n",
        "print(f\"\\n‚úÖ Created: {zip_filename}\")\n",
        "\n",
        "# Download the zip file\n",
        "from google.colab import files\n",
        "files.download(zip_filename)\n",
        "\n",
        "print(\"\\nüì¶ Download started!\")\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"NEXT STEPS\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\n1. Extract the downloaded zip file\")\n",
        "print(\"2. Copy files to your project's ml-models/ directory:\")\n",
        "print(\"   - food_model_v1.pth\")\n",
        "print(\"   - class_to_idx.json\")\n",
        "print(\"   - model_config.json\")\n",
        "print(\"\\n3. The backend predictor will automatically load the model\")\n",
        "print(\"\\n4. Test the API:\")\n",
        "print(\"   cd backend\")\n",
        "print(\"   python -m uvicorn app.main:app --reload\")\n",
        "print(\"\\n5. Upload a food image and get predictions!\")\n",
        "print(\"\\n\" + \"=\" * 60)"
      ],
      "metadata": {
        "id": "download_model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: Copy to Google Drive for backup\n",
        "if os.path.exists('/content/drive/MyDrive/NutriLearn_Models'):\n",
        "    import shutil\n",
        "    \n",
        "    drive_path = '/content/drive/MyDrive/NutriLearn_Models'\n",
        "    \n",
        "    # Copy all model files\n",
        "    for filename in ['food_model_v1.pth', 'class_to_idx.json', 'model_config.json', \n",
        "                     'evaluation_results.json', 'confusion_matrix.png']:\n",
        "        src = f'ml-models/{filename}'\n",
        "        if os.path.exists(src):\n",
        "            dst = f'{drive_path}/{filename}'\n",
        "            shutil.copy(src, dst)\n",
        "            print(f\"‚úì Copied {filename} to Google Drive\")\n",
        "    \n",
        "    # Also copy the zip\n",
        "    shutil.copy(zip_filename, f'{drive_path}/{zip_filename}')\n",
        "    print(f\"\\n‚úÖ All files backed up to Google Drive!\")\n",
        "    print(f\"Location: {drive_path}\")\n",
        "else:\n",
        "    print(\"Google Drive not mounted. Skipping backup.\")"
      ],
      "metadata": {
        "id": "backup_to_drive"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. View MLflow Results (Optional)"
      ],
      "metadata": {
        "id": "mlflow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start MLflow UI (runs in background)\n",
        "# Note: In Colab, you'll need to use ngrok to access the UI\n",
        "\n",
        "# Install pyngrok\n",
        "!pip install -q pyngrok\n",
        "\n",
        "# Start MLflow UI\n",
        "from pyngrok import ngrok\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "# Start MLflow server\n",
        "mlflow_process = subprocess.Popen(['mlflow', 'ui', '--port', '5000'])\n",
        "time.sleep(5)\n",
        "\n",
        "# Create ngrok tunnel\n",
        "public_url = ngrok.connect(5000)\n",
        "print(f\"MLflow UI available at: {public_url}\")\n",
        "print(\"\\nClick the link above to view your experiments!\")"
      ],
      "metadata": {
        "id": "mlflow_ui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìù Training Summary and Tips\n",
        "\n",
        "### üéØ Expected Performance\n",
        "\n",
        "| Model | Accuracy | Speed | Parameters | Best For |\n",
        "|-------|----------|-------|------------|----------|\n",
        "| MobileNetV2 | 75-80% | Fast | 3.5M | Production, Mobile |\n",
        "| EfficientNet-B0 | 78-83% | Medium | 5.3M | Balanced |\n",
        "| ResNet50 | 80-85% | Slow | 25.6M | Best Accuracy |\n",
        "\n",
        "### ‚ö° Training Tips\n",
        "\n",
        "**Hardware:**\n",
        "- Always use GPU (Runtime ‚Üí Change runtime type ‚Üí GPU)\n",
        "- T4 GPU: ~1-2 hours training time\n",
        "- CPU: ~15+ hours (not recommended)\n",
        "\n",
        "**Hyperparameters:**\n",
        "- Increase `batch_size` if you have more GPU memory (32 ‚Üí 64 ‚Üí 128)\n",
        "- Decrease `batch_size` if you get OOM errors\n",
        "- Try different learning rates: 0.001 (default), 0.0001 (fine-tuning)\n",
        "- More epochs = better accuracy (but watch for overfitting)\n",
        "\n",
        "**Model Selection:**\n",
        "- Start with MobileNetV2 for quick experiments\n",
        "- Use EfficientNet-B0 for production (best balance)\n",
        "- Use ResNet50 if accuracy is critical\n",
        "\n",
        "### üêõ Troubleshooting\n",
        "\n",
        "**Out of Memory (OOM):**\n",
        "```python\n",
        "# Reduce batch size\n",
        "!python train_model.py --batch_size 32  # or 16\n",
        "```\n",
        "\n",
        "**Slow Training:**\n",
        "- Check GPU is enabled\n",
        "- Reduce number of workers: `--num_workers 2`\n",
        "- Use smaller model: MobileNetV2\n",
        "\n",
        "**Low Accuracy:**\n",
        "- Train for more epochs: `--epochs 30`\n",
        "- Try different model: EfficientNet or ResNet\n",
        "- Check data augmentation is working\n",
        "\n",
        "### üöÄ Deployment Checklist\n",
        "\n",
        "- [ ] Model trained and downloaded\n",
        "- [ ] Files copied to `ml-models/` directory\n",
        "- [ ] Backend predictor tested locally\n",
        "- [ ] API endpoints working\n",
        "- [ ] Frontend integrated\n",
        "- [ ] Docker container built\n",
        "- [ ] Deployed to production\n",
        "\n",
        "### üìö Resources\n",
        "\n",
        "**Dataset:**\n",
        "- [Food-101 Dataset](https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/)\n",
        "- [Food-101 Paper](https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/static/bossard_eccv14_food-101.pdf)\n",
        "\n",
        "**PyTorch:**\n",
        "- [Transfer Learning Tutorial](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)\n",
        "- [PyTorch Documentation](https://pytorch.org/docs/stable/index.html)\n",
        "- [torchvision Models](https://pytorch.org/vision/stable/models.html)\n",
        "\n",
        "**MLOps:**\n",
        "- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)\n",
        "- [MLflow Tracking](https://mlflow.org/docs/latest/tracking.html)\n",
        "\n",
        "### üéì Learning More\n",
        "\n",
        "**Improve Model Performance:**\n",
        "1. Try ensemble methods (combine multiple models)\n",
        "2. Use test-time augmentation\n",
        "3. Fine-tune more layers\n",
        "4. Collect more training data\n",
        "5. Use advanced augmentation (CutMix, MixUp)\n",
        "\n",
        "**Production Optimization:**\n",
        "1. Convert to ONNX for faster inference\n",
        "2. Quantize model for mobile deployment\n",
        "3. Use TorchScript for production\n",
        "4. Implement model caching\n",
        "5. Add A/B testing for model versions\n",
        "\n",
        "---\n",
        "\n",
        "**üéâ Congratulations!** You've successfully trained a food classification model!\n",
        "\n",
        "**Questions or Issues?**\n",
        "- Check the [GitHub repository](https://github.com/yourusername/nutrilearn-ai)\n",
        "- Review the MODEL_TRAINING_GUIDE.md\n",
        "- Open an issue for bugs or questions\n",
        "\n",
        "**Happy Training! üöÄ**"
      ],
      "metadata": {
        "id": "notes"
      }
    }
  ]
}
